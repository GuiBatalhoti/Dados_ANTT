{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibatalhoti/Dados_ANTT/_env/lib/python3.12/site-packages/geopandas/io/file.py:399: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  as_dt = pd.to_datetime(df[k], errors=\"ignore\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_da_ocorrencia</th>\n",
       "      <th>km</th>\n",
       "      <th>trecho</th>\n",
       "      <th>sentido</th>\n",
       "      <th>tipo_de_acidente</th>\n",
       "      <th>automovel</th>\n",
       "      <th>bicicleta</th>\n",
       "      <th>caminhao</th>\n",
       "      <th>moto</th>\n",
       "      <th>onibus</th>\n",
       "      <th>...</th>\n",
       "      <th>mortos</th>\n",
       "      <th>concessionaria</th>\n",
       "      <th>data_hora</th>\n",
       "      <th>com_vitima</th>\n",
       "      <th>estado</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>316.0</td>\n",
       "      <td>BR-101/SC</td>\n",
       "      <td>Decrescente</td>\n",
       "      <td>Saída de pista</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>viacosteira</td>\n",
       "      <td>2021-05-01 12:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>SC</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>-28.425440</td>\n",
       "      <td>-48.857996</td>\n",
       "      <td>POINT (-48.85800 -28.42544)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>316.0</td>\n",
       "      <td>BR-101/SC</td>\n",
       "      <td>Decrescente</td>\n",
       "      <td>Saída de pista</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>viacosteira</td>\n",
       "      <td>2021-05-01 12:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>SC</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>-28.426395</td>\n",
       "      <td>-48.859912</td>\n",
       "      <td>POINT (-48.85991 -28.42639)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_da_ocorrencia     km     trecho      sentido tipo_de_acidente  automovel  \\\n",
       "0               1  316.0  BR-101/SC  Decrescente   Saída de pista          2   \n",
       "1               1  316.0  BR-101/SC  Decrescente   Saída de pista          2   \n",
       "\n",
       "   bicicleta  caminhao  moto  onibus  ...  mortos  concessionaria  \\\n",
       "0          0         0     0       0  ...       0     viacosteira   \n",
       "1          0         0     0       0  ...       0     viacosteira   \n",
       "\n",
       "            data_hora  com_vitima  estado   ano  mes   latitude  longitude  \\\n",
       "0 2021-05-01 12:10:00       False      SC  2021    5 -28.425440 -48.857996   \n",
       "1 2021-05-01 12:10:00       False      SC  2021    5 -28.426395 -48.859912   \n",
       "\n",
       "                      geometry  \n",
       "0  POINT (-48.85800 -28.42544)  \n",
       "1  POINT (-48.85991 -28.42639)  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd # type: ignore\n",
    "\n",
    "def carregar_geojson_em_dataframe(caminho_arquivo):\n",
    "    try:\n",
    "        # Carrega o GeoJSON usando o geopandas\n",
    "        gdf = gpd.read_file(caminho_arquivo)\n",
    "        return gdf\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao abrir o arquivo GeoJSON: {e}\")\n",
    "        return None\n",
    "\n",
    "acidentes_df = carregar_geojson_em_dataframe(\"../data/ANTT/BR-101-SC/acidentes_br101sc.geojson\")\n",
    "acidentes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conta a quantidade de valores vazios em latitude\n",
    "acidentes_df['latitude'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_da_ocorrencia', 'km', 'trecho', 'sentido', 'tipo_de_acidente',\n",
       "       'automovel', 'bicicleta', 'caminhao', 'moto', 'onibus', 'outros',\n",
       "       'tracao_animal', 'transporte_de_cargas_especiais', 'trator_maquinas',\n",
       "       'utilitarios', 'ilesos', 'levemente_feridos', 'moderadamente_feridos',\n",
       "       'gravemente_feridos', 'mortos', 'concessionaria', 'data_hora',\n",
       "       'com_vitima', 'estado', 'ano', 'mes', 'latitude', 'longitude',\n",
       "       'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acidentes_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibatalhoti/Dados_ANTT/_env/lib/python3.12/site-packages/geopandas/io/file.py:399: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  as_dt = pd.to_datetime(df[k], errors=\"ignore\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regiao</th>\n",
       "      <th>estado</th>\n",
       "      <th>codigo_estacao</th>\n",
       "      <th>nome_estacao</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>alt</th>\n",
       "      <th>data_fundacao</th>\n",
       "      <th>nome_arquivo</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>RS</td>\n",
       "      <td>MOSTARDAS</td>\n",
       "      <td>A878</td>\n",
       "      <td>-31.248333</td>\n",
       "      <td>-50.906389</td>\n",
       "      <td>3.82</td>\n",
       "      <td>2008-03-11</td>\n",
       "      <td>../data/INMET/2022/INMET_S_RS_A878_MOSTARDAS_0...</td>\n",
       "      <td>POINT (-50.90639 -31.24833)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CO</td>\n",
       "      <td>GO</td>\n",
       "      <td>ITUMBIARA</td>\n",
       "      <td>A035</td>\n",
       "      <td>-18.409722</td>\n",
       "      <td>-49.191944</td>\n",
       "      <td>491.17</td>\n",
       "      <td>2007-11-01</td>\n",
       "      <td>../data/INMET/2022/INMET_CO_GO_A035_ITUMBIARA_...</td>\n",
       "      <td>POINT (-49.19194 -18.40972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>RS</td>\n",
       "      <td>DOM PEDRITO</td>\n",
       "      <td>A881</td>\n",
       "      <td>-31.002500</td>\n",
       "      <td>-54.618056</td>\n",
       "      <td>150.00</td>\n",
       "      <td>2010-04-23</td>\n",
       "      <td>../data/INMET/2022/INMET_S_RS_A881_DOM PEDRITO...</td>\n",
       "      <td>POINT (-54.61806 -31.00250)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CO</td>\n",
       "      <td>MT</td>\n",
       "      <td>VILA BELA DA SANTISSIMA TRINDADE</td>\n",
       "      <td>A922</td>\n",
       "      <td>-15.062778</td>\n",
       "      <td>-59.873056</td>\n",
       "      <td>213.00</td>\n",
       "      <td>2006-12-01</td>\n",
       "      <td>../data/INMET/2022/INMET_CO_MT_A922_VILA BELA ...</td>\n",
       "      <td>POINT (-59.87306 -15.06278)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SE</td>\n",
       "      <td>MG</td>\n",
       "      <td>ALMENARA</td>\n",
       "      <td>A508</td>\n",
       "      <td>-16.166667</td>\n",
       "      <td>-40.687778</td>\n",
       "      <td>189.11</td>\n",
       "      <td>2002-12-15</td>\n",
       "      <td>../data/INMET/2022/INMET_SE_MG_A508_ALMENARA_0...</td>\n",
       "      <td>POINT (-40.68778 -16.16667)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>S</td>\n",
       "      <td>RS</td>\n",
       "      <td>CAMAQUA</td>\n",
       "      <td>A838</td>\n",
       "      <td>-30.807953</td>\n",
       "      <td>-51.834240</td>\n",
       "      <td>92.30</td>\n",
       "      <td>2006-12-12</td>\n",
       "      <td>../data/INMET/2021/INMET_S_RS_A838_CAMAQUA_01-...</td>\n",
       "      <td>POINT (-51.83424 -30.80795)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>NE</td>\n",
       "      <td>BA</td>\n",
       "      <td>BOM JESUS DA LAPA</td>\n",
       "      <td>A418</td>\n",
       "      <td>-13.251111</td>\n",
       "      <td>-43.405278</td>\n",
       "      <td>447.75</td>\n",
       "      <td>2007-05-18</td>\n",
       "      <td>../data/INMET/2021/INMET_NE_BA_A418_BOM JESUS ...</td>\n",
       "      <td>POINT (-43.40528 -13.25111)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>N</td>\n",
       "      <td>AM</td>\n",
       "      <td>S. G. DA CACHOEIRA</td>\n",
       "      <td>A134</td>\n",
       "      <td>-0.125207</td>\n",
       "      <td>-67.061246</td>\n",
       "      <td>79.67</td>\n",
       "      <td>2011-08-31</td>\n",
       "      <td>../data/INMET/2021/INMET_N_AM_A134_S. G. DA CA...</td>\n",
       "      <td>POINT (-67.06125 -0.12521)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>SE</td>\n",
       "      <td>MG</td>\n",
       "      <td>PASSOS</td>\n",
       "      <td>A516</td>\n",
       "      <td>-20.745237</td>\n",
       "      <td>-46.633916</td>\n",
       "      <td>781.70</td>\n",
       "      <td>2006-07-16</td>\n",
       "      <td>../data/INMET/2021/INMET_SE_MG_A516_PASSOS_01-...</td>\n",
       "      <td>POINT (-46.63392 -20.74524)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>NE</td>\n",
       "      <td>BA</td>\n",
       "      <td>FEIRA DE SANTANA</td>\n",
       "      <td>A413</td>\n",
       "      <td>-12.196111</td>\n",
       "      <td>-38.967500</td>\n",
       "      <td>229.64</td>\n",
       "      <td>2007-05-26</td>\n",
       "      <td>../data/INMET/2021/INMET_NE_BA_A413_FEIRA DE S...</td>\n",
       "      <td>POINT (-38.96750 -12.19611)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2876 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     regiao estado                    codigo_estacao nome_estacao        lat  \\\n",
       "0         S     RS                         MOSTARDAS         A878 -31.248333   \n",
       "1        CO     GO                         ITUMBIARA         A035 -18.409722   \n",
       "2         S     RS                       DOM PEDRITO         A881 -31.002500   \n",
       "3        CO     MT  VILA BELA DA SANTISSIMA TRINDADE         A922 -15.062778   \n",
       "4        SE     MG                          ALMENARA         A508 -16.166667   \n",
       "...     ...    ...                               ...          ...        ...   \n",
       "2871      S     RS                           CAMAQUA         A838 -30.807953   \n",
       "2872     NE     BA                 BOM JESUS DA LAPA         A418 -13.251111   \n",
       "2873      N     AM                S. G. DA CACHOEIRA         A134  -0.125207   \n",
       "2874     SE     MG                            PASSOS         A516 -20.745237   \n",
       "2875     NE     BA                  FEIRA DE SANTANA         A413 -12.196111   \n",
       "\n",
       "           long     alt data_fundacao  \\\n",
       "0    -50.906389    3.82    2008-03-11   \n",
       "1    -49.191944  491.17    2007-11-01   \n",
       "2    -54.618056  150.00    2010-04-23   \n",
       "3    -59.873056  213.00    2006-12-01   \n",
       "4    -40.687778  189.11    2002-12-15   \n",
       "...         ...     ...           ...   \n",
       "2871 -51.834240   92.30    2006-12-12   \n",
       "2872 -43.405278  447.75    2007-05-18   \n",
       "2873 -67.061246   79.67    2011-08-31   \n",
       "2874 -46.633916  781.70    2006-07-16   \n",
       "2875 -38.967500  229.64    2007-05-26   \n",
       "\n",
       "                                           nome_arquivo  \\\n",
       "0     ../data/INMET/2022/INMET_S_RS_A878_MOSTARDAS_0...   \n",
       "1     ../data/INMET/2022/INMET_CO_GO_A035_ITUMBIARA_...   \n",
       "2     ../data/INMET/2022/INMET_S_RS_A881_DOM PEDRITO...   \n",
       "3     ../data/INMET/2022/INMET_CO_MT_A922_VILA BELA ...   \n",
       "4     ../data/INMET/2022/INMET_SE_MG_A508_ALMENARA_0...   \n",
       "...                                                 ...   \n",
       "2871  ../data/INMET/2021/INMET_S_RS_A838_CAMAQUA_01-...   \n",
       "2872  ../data/INMET/2021/INMET_NE_BA_A418_BOM JESUS ...   \n",
       "2873  ../data/INMET/2021/INMET_N_AM_A134_S. G. DA CA...   \n",
       "2874  ../data/INMET/2021/INMET_SE_MG_A516_PASSOS_01-...   \n",
       "2875  ../data/INMET/2021/INMET_NE_BA_A413_FEIRA DE S...   \n",
       "\n",
       "                         geometry  \n",
       "0     POINT (-50.90639 -31.24833)  \n",
       "1     POINT (-49.19194 -18.40972)  \n",
       "2     POINT (-54.61806 -31.00250)  \n",
       "3     POINT (-59.87306 -15.06278)  \n",
       "4     POINT (-40.68778 -16.16667)  \n",
       "...                           ...  \n",
       "2871  POINT (-51.83424 -30.80795)  \n",
       "2872  POINT (-43.40528 -13.25111)  \n",
       "2873   POINT (-67.06125 -0.12521)  \n",
       "2874  POINT (-46.63392 -20.74524)  \n",
       "2875  POINT (-38.96750 -12.19611)  \n",
       "\n",
       "[2876 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estacoes_proximas = carregar_geojson_em_dataframe(\"estacoes_inmet.geojson\")\n",
    "estacoes_proximas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 48\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(merged_data)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# acidentes_sample = acidentes_df.sample(15)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# datas_climaticas = pd.read_csv(\"datas_climaticas.csv\")\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m acidentes_com_estacoes \u001b[38;5;241m=\u001b[39m find_nearest_weather_station(acidentes_df, estacoes_proximas)\n\u001b[1;32m     49\u001b[0m acidentes_com_estacoes\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36mfind_nearest_weather_station\u001b[0;34m(accidents_df, weather_stations_df, radius_km)\u001b[0m\n\u001b[1;32m     20\u001b[0m accident_location \u001b[38;5;241m=\u001b[39m (accident_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m], accident_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#print(f\"Procurando estação climática mais próxima para o acidente em {accident_location}\")\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Calcula a distância para cada estação climática\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m weather_stations_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m weather_stations_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: geodesic(accident_location, (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m'\u001b[39m]))\u001b[38;5;241m.\u001b[39mkilometers, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Filtra estações dentro do raio especificado\u001b[39;00m\n\u001b[1;32m     30\u001b[0m nearby_stations \u001b[38;5;241m=\u001b[39m weather_stations_df[weather_stations_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m radius_km]\n",
      "File \u001b[0;32m~/Dados_ANTT/_env/lib/python3.12/site-packages/geopandas/geodataframe.py:1586\u001b[0m, in \u001b[0;36mGeoDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;129m@doc\u001b[39m(pd\u001b[38;5;241m.\u001b[39mDataFrame)\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, result_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, args\u001b[38;5;241m=\u001b[39m(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1586\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m   1587\u001b[0m         func, axis\u001b[38;5;241m=\u001b[39maxis, raw\u001b[38;5;241m=\u001b[39mraw, result_type\u001b[38;5;241m=\u001b[39mresult_type, args\u001b[38;5;241m=\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1588\u001b[0m     )\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;66;03m# pandas <1.4 re-attach last geometry col if lost\u001b[39;00m\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1591\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m compat\u001b[38;5;241m.\u001b[39mPANDAS_GE_14\n\u001b[1;32m   1592\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, GeoDataFrame)\n\u001b[1;32m   1593\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_geometry_column_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     ):\n",
      "File \u001b[0;32m~/Dados_ANTT/_env/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Dados_ANTT/_env/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/Dados_ANTT/_env/lib/python3.12/site-packages/pandas/core/apply.py:1068\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m-> 1068\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/Dados_ANTT/_env/lib/python3.12/site-packages/pandas/core/apply.py:1118\u001b[0m, in \u001b[0;36mFrameApply.wrap_results\u001b[0;34m(self, results, res_index)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     result \u001b[38;5;241m=\u001b[39m constructor_sliced(results, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1118\u001b[0m     result \u001b[38;5;241m=\u001b[39m constructor_sliced(results)\n\u001b[1;32m   1119\u001b[0m result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m res_index\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Dados_ANTT/_env/lib/python3.12/site-packages/geopandas/geodataframe.py:1645\u001b[0m, in \u001b[0;36mGeoDataFrame._constructor_sliced.<locals>._geodataframe_constructor_sliced\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_geodataframe_constructor_sliced\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;124;03m    A specialized (Geo)Series constructor which can fall back to a\u001b[39;00m\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;124;03m    Series if a certain operation does not produce geometries:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1643\u001b[0m \u001b[38;5;124;03m      checking the identity of the index)\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1645\u001b[0m     srs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1646\u001b[0m     is_row_proxy \u001b[38;5;241m=\u001b[39m srs\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_geometry_type(srs) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_row_proxy:\n",
      "File \u001b[0;32m~/Dados_ANTT/_env/lib/python3.12/site-packages/pandas/core/series.py:537\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    535\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[0;32m--> 537\u001b[0m     data, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_dict(data, index, dtype)\n\u001b[1;32m    538\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    539\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Dados_ANTT/_env/lib/python3.12/site-packages/pandas/core/series.py:651\u001b[0m, in \u001b[0;36mSeries._init_dict\u001b[0;34m(self, data, index, dtype)\u001b[0m\n\u001b[1;32m    648\u001b[0m     keys, values \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;241m0\u001b[39m), []\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# Input is now list-like, so rely on \"standard\" construction:\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m s \u001b[38;5;241m=\u001b[39m Series(values, index\u001b[38;5;241m=\u001b[39mkeys, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    653\u001b[0m \u001b[38;5;66;03m# Now we just make sure the order is respected, if any\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Dados_ANTT/_env/lib/python3.12/site-packages/pandas/core/series.py:490\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    487\u001b[0m name \u001b[38;5;241m=\u001b[39m ibase\u001b[38;5;241m.\u001b[39mmaybe_extract_name(name, data, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 490\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dtype(dtype)\n",
      "File \u001b[0;32m~/Dados_ANTT/_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:7649\u001b[0m, in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   7647\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Index(index_like, copy\u001b[38;5;241m=\u001b[39mcopy, tupleize_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   7648\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 7649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Index(index_like, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/Dados_ANTT/_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:565\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[1;32m    562\u001b[0m         data \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39m_dtype_obj)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m     arr \u001b[38;5;241m=\u001b[39m sanitize_array(data, \u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex must be specified when data is not list-like\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/Dados_ANTT/_env/lib/python3.12/site-packages/pandas/core/construction.py:654\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    651\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m _try_cast(data, dtype, copy)\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 654\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m maybe_convert_platform(data)\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subarr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    656\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n",
      "File \u001b[0;32m~/Dados_ANTT/_env/lib/python3.12/site-packages/pandas/core/dtypes/cast.py:139\u001b[0m, in \u001b[0;36mmaybe_convert_platform\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m _dtype_obj:\n\u001b[1;32m    138\u001b[0m     arr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, arr)\n\u001b[0;32m--> 139\u001b[0m     arr \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(arr)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def find_nearest_weather_station(accidents_df, weather_stations_df, radius_km=50):\n",
    "    # Copy the input DataFrames to avoid modifying the original DataFrames\n",
    "    accidents_df = accidents_df.copy()\n",
    "    weather_stations_df = weather_stations_df.copy()\n",
    "\n",
    "    # Remover linhas com valores NaN em coordenadas\n",
    "    accidents_df = accidents_df.dropna(subset=['latitude', 'longitude'])\n",
    "    weather_stations_df = weather_stations_df.dropna(subset=['lat', 'long'])\n",
    "\n",
    "    # Lista para armazenar resultados\n",
    "    merged_data = []\n",
    "\n",
    "    # Itera sobre cada linha do DataFrame de acidentes\n",
    "    for _, accident_row in accidents_df.iterrows():\n",
    "\n",
    "        accident_location = (accident_row['latitude'], accident_row['longitude'])\n",
    "\n",
    "        #print(f\"Procurando estação climática mais próxima para o acidente em {accident_location}\")\n",
    "\n",
    "        # Calcula a distância para cada estação climática\n",
    "        weather_stations_df['distance'] = weather_stations_df.apply(\n",
    "            lambda row: geodesic(accident_location, (row['lat'], row['long'])).kilometers, axis=1\n",
    "        )\n",
    "\n",
    "        # Filtra estações dentro do raio especificado\n",
    "        nearby_stations = weather_stations_df[weather_stations_df['distance'] <= radius_km]\n",
    "\n",
    "        if not nearby_stations.empty:\n",
    "            # Encontra a estação mais próxima\n",
    "            nearest_station = nearby_stations.loc[nearby_stations['distance'].idxmin()]\n",
    "            combined_row = {**accident_row.to_dict(), **nearest_station.to_dict()}\n",
    "        else:\n",
    "            # Se nenhuma estação estiver próxima, preencha com NaN\n",
    "            combined_row = {**accident_row.to_dict(), **{col: np.nan for col in weather_stations_df.columns}}\n",
    "\n",
    "        merged_data.append(combined_row)\n",
    "\n",
    "    # Retorna o DataFrame combinado\n",
    "    return pd.DataFrame(merged_data)\n",
    "\n",
    "# acidentes_sample = acidentes_df.sample(15)\n",
    "# datas_climaticas = pd.read_csv(\"datas_climaticas.csv\")\n",
    "\n",
    "acidentes_com_estacoes = find_nearest_weather_station(acidentes_df, estacoes_proximas)\n",
    "acidentes_com_estacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acidentes_com_estacoes.to_csv(\"./secundario/acidentes_com_estacoes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def load_and_concat_unique_data_with_metadata(df, years=[2020, 2021, 2022, 2023]):\n",
    "    \"\"\"\n",
    "    Lê arquivos CSV baseados em valores únicos na coluna 'nome_arquivo' de um DataFrame,\n",
    "    processa para anos especificados e concatena sem duplicações, adicionando as informações\n",
    "    das 8 primeiras linhas como novas colunas.\n",
    "\n",
    "    Parâmetros:\n",
    "        df (pd.DataFrame): DataFrame contendo a coluna 'nome_arquivo' com caminhos dos arquivos.\n",
    "        years (list): Lista de anos de interesse para filtrar os dados (default: [2020, 2021, 2022, 2023]).\n",
    "\n",
    "    Retorna:\n",
    "        pd.DataFrame: Um DataFrame concatenado sem duplicações, com as colunas extras.\n",
    "    \"\"\"\n",
    "    # Obter valores únicos na coluna 'nome_arquivo'\n",
    "    unique_files = df['nome_arquivo'].dropna().unique()\n",
    "\n",
    "    # Inicializa o DataFrame vazio para concatenar os resultados\n",
    "    concatenated_df = pd.DataFrame()\n",
    "\n",
    "    # Expressão regular para encontrar o ano no nome do arquivo\n",
    "    year_pattern = r'\\d{4}'  # padrão para encontrar ano de 4 dígitos\n",
    "\n",
    "    # Conjunto para armazenar arquivos processados e evitar duplicações\n",
    "    processed_files = set()\n",
    "\n",
    "    for base_path in unique_files:\n",
    "        # Encontra o ano presente no nome do arquivo\n",
    "        match = re.search(year_pattern, base_path)\n",
    "        if match:\n",
    "            current_year = match.group()  # Ano encontrado no caminho do arquivo\n",
    "            \n",
    "            for year in years:\n",
    "                # Substitui o ano encontrado no caminho do arquivo pelo ano da iteração\n",
    "                file_path = base_path.replace(current_year, str(year))\n",
    "\n",
    "                if file_path not in processed_files and os.path.exists(file_path):\n",
    "                    print(f\"Lendo arquivo: {file_path}\")\n",
    "                    processed_files.add(file_path)  # Marca o arquivo como processado\n",
    "                    \n",
    "                    try:\n",
    "                        # Lê as primeiras 8 linhas do arquivo para extrair as variáveis adicionais\n",
    "                        with open(file_path, 'r', encoding='latin1') as file:\n",
    "                            first_8_lines = [next(file) for _ in range(8)]\n",
    "\n",
    "                        # Extraindo as variáveis a partir das 8 primeiras linhas\n",
    "                        metadata = {\n",
    "                            \"REGIAO\": first_8_lines[0].split(';')[1].strip(),\n",
    "                            \"UF\": first_8_lines[1].split(';')[1].strip(),\n",
    "                            \"ESTACAO\": first_8_lines[2].split(';')[1].strip(),\n",
    "                            \"CODIGO_WMO\": first_8_lines[3].split(';')[1].strip(),\n",
    "                            \"LATITUDE\": first_8_lines[4].split(';')[1].strip(),\n",
    "                            \"LONGITUDE\": first_8_lines[5].split(';')[1].strip(),\n",
    "                            \"ALTITUDE\": first_8_lines[6].split(';')[1].strip(),\n",
    "                            \"DATA_FUNDACAO\": first_8_lines[7].split(';')[1].strip()\n",
    "                        }\n",
    "\n",
    "                        # Lê o resto do arquivo ignorando as 8 primeiras linhas\n",
    "                        temp_df = pd.read_csv(\n",
    "                            file_path,\n",
    "                            skiprows=8,\n",
    "                            encoding='latin1',\n",
    "                            sep=';',  # Especifica o delimitador correto\n",
    "                            engine='python'         # Usa o motor Python para maior flexibilidade\n",
    "                        )\n",
    "                        # Adiciona as variáveis extraídas como novas colunas\n",
    "                        for key, value in metadata.items():\n",
    "                            temp_df[key] = value\n",
    "\n",
    "                        # Adiciona o arquivo lido ao DataFrame concatenado\n",
    "                        concatenated_df = pd.concat([concatenated_df, temp_df], ignore_index=True)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erro ao processar {file_path}: {e}\")\n",
    "                else:\n",
    "                    print(f\"Arquivo já processado ou não encontrado: {file_path}\")\n",
    "        else:\n",
    "            print(f\"Ano não encontrado no arquivo {base_path}\")\n",
    "\n",
    "    # Remove duplicatas do DataFrame final considerando todas as colunas\n",
    "    concatenated_df = concatenated_df.drop_duplicates()\n",
    "\n",
    "    return concatenated_df\n",
    "        \n",
    "# retira warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Carrega os dados de acidentes com estações climáticas\n",
    "datas_climaticas = load_and_concat_unique_data_with_metadata(acidentes_com_estacoes)\n",
    "datas_climaticas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # verifica duplicatas\n",
    "# print(datas_climaticas.duplicated().sum())\n",
    "# # verifica Data value counts\n",
    "# print(datas_climaticas['Data'].value_counts())\n",
    "datas_climaticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_climaticas.to_csv('./secundario/datas_climaticas.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # type: ignore\n",
    "from geopy.distance import geodesic # type: ignore\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def find_nearest_weather_station_with_time(accidents_df, weather_stations_df, radius_km=50):\n",
    "    # Função para converter vírgulas para ponto e depois para float\n",
    "    def convert_to_float(value):\n",
    "        if isinstance(value, str):  # Verifica se o valor é uma string\n",
    "            value = value.replace(',', '.')  # Substitui vírgula por ponto\n",
    "        return float(value) if value else 0.0  # Converte para float, ou 0.0 se for None ou vazio\n",
    "\n",
    "    # Copiar os DataFrames de entrada para evitar modificar os originais\n",
    "    accidents_df = accidents_df.copy()\n",
    "    weather_stations_df = weather_stations_df.copy()\n",
    "\n",
    "    # Remover linhas com valores NaN em coordenadas\n",
    "    accidents_df = accidents_df.dropna(subset=['latitude', 'longitude'])\n",
    "    weather_stations_df = weather_stations_df.dropna(subset=['LATITUDE', 'LONGITUDE'])\n",
    "\n",
    "    # Converter as colunas de latitude e longitude para float (com correção de vírgula)\n",
    "    weather_stations_df['LATITUDE'] = weather_stations_df['LATITUDE'].apply(convert_to_float)\n",
    "    weather_stations_df['LONGITUDE'] = weather_stations_df['LONGITUDE'].apply(convert_to_float)\n",
    "\n",
    "    # Converter as colunas de data e hora para datetime\n",
    "    accidents_df['data_hora'] = pd.to_datetime(accidents_df['data_hora'])\n",
    "    \n",
    "    # Ajuste da coluna de hora no dataframe de clima\n",
    "    weather_stations_df['datetime'] = pd.to_datetime(weather_stations_df['Data'] + ' ' + weather_stations_df['Hora UTC'].str.replace(' UTC', ''), format='%Y/%m/%d %H%M')\n",
    "\n",
    "    # Lista para armazenar resultados\n",
    "    merged_data = []\n",
    "\n",
    "    # Itera sobre cada linha do DataFrame de acidentes\n",
    "    for _, accident_row in accidents_df.iterrows():\n",
    "        accident_location = (accident_row['latitude'], accident_row['longitude'])\n",
    "        accident_time = accident_row['data_hora']\n",
    "\n",
    "        # print(f\"Procurando estação climática mais próxima para o acidente em {accident_location} na hora {accident_time}\")\n",
    "\n",
    "        # Calcula a distância para cada estação climática\n",
    "        weather_stations_df['distance'] = weather_stations_df.apply(\n",
    "            lambda row: geodesic(accident_location, (row['LATITUDE'], row['LONGITUDE'])).kilometers, axis=1\n",
    "        )\n",
    "\n",
    "        # Filtra estações dentro do raio especificado\n",
    "        nearby_stations = weather_stations_df[weather_stations_df['distance'] <= radius_km]\n",
    "\n",
    "        if not nearby_stations.empty:\n",
    "            # Encontrar a estação mais próxima em termos de data/hora\n",
    "            nearby_stations['time_diff'] = (nearby_stations['datetime'] - accident_time).abs()\n",
    "\n",
    "            # Encontra a estação com a menor diferença de tempo\n",
    "            nearest_station = nearby_stations.loc[nearby_stations['time_diff'].idxmin()]\n",
    "            \n",
    "            # Combina os dados do acidente e da estação climática\n",
    "            combined_row = {**accident_row.to_dict(), **nearest_station.to_dict()}\n",
    "        else:\n",
    "            # Se nenhuma estação estiver dentro do raio, preenche com NaN\n",
    "            combined_row = {**accident_row.to_dict(), **{col: np.nan for col in weather_stations_df.columns}}\n",
    "\n",
    "        merged_data.append(combined_row)\n",
    "\n",
    "    # Retorna o DataFrame combinado\n",
    "    return pd.DataFrame(merged_data)\n",
    "\n",
    "\n",
    "acidentes_com_estacoes = find_nearest_weather_station_with_time(acidentes_df, datas_climaticas)\n",
    "acidentes_com_estacoes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acidentes_com_estacoes.to_csv('./secundario/acidentes_com_estacoes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tente com 'latin1' ou 'iso-8859-1'\n",
    "# clima_df = pd.read_csv('../data/INMET/2023/INMET_SE_SP_A768_TUPA_01-01-2023_A_31-12-2023.csv', \n",
    "#                        sep=';', \n",
    "#                        skiprows=8, \n",
    "#                        encoding='latin1')  # Ou experimente 'iso-8859-1'\n",
    "# clima_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acidentes_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('rodo_estacoes.csv')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
